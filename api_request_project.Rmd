---
title: "API_request_project"
author: "Justin Herman"
date: "8/19/2019"
output:
  html_document:
    theme: "simplex"
    highlight: 'pygments'
---

<style>h1{text-transform: capitalize}</style>
<style>h2{text-transform: capitalize}</style>
<style>h3{text-transform: capitalize}</style>
<style>p:first-letter {text-transform: capitalize}</style>
<style>li:first-letter {text-transform: capitalize}</style>

<style type="text/css">body{ /* Normal  */ font-size: 18px;}}</style>

# Overview {.tabset .tabset-fade}

The idea behind this project is to form an ETL pipeline for an API.  I will access financial data API from [link](https://financialmodelingprep.com/developer/docs/) and build out a my_sql db. I use R and R libraries as my interface with the API and my_sql database.  All packages are listed in the first section **Library Import** and the report is created as an html document and uploaded to my GitHub [here](https://github.com/justinherman42/Company_project) periodically for version control. 

I decided to explore US regional banks sized 50-500 billion. First, I build some functions to access API and convert JSON data to an R Dataframe. This function cleans the data and preps it for our sql database.  Functions are then used to insert that dataframe into a my_sql db. Once the data is in my_sql the data is displayed by running queries from within R, and the query results are displayed in a datatable in R. Datatables are convenient as they allow the user to explore the data more than a static print. SQL Windows functions are then used to manipulate the sql data and explore aggregated behaviors.  Some of those functions are generalized to be able to handle any numeric column.  Generally, the functions are there to show an understanding of SQL and how to perform data manipulation.     

## Build out  functions  {.tabset .tabset-fade}
In the section below, the API is accessed and the JSON data is converted and inserted in mysql db.  After reading through all the subsections below, please see windows functions section to the right for more exploration. 

### Library import
```{r,message=F,warning=FALSE}
rm(list=ls())
library(httr)
library(jsonlite)
library(lubridate)
library(tidyverse)
library(RMariaDB)
library(DT)
library(knitr)
library(kableExtra)


pack_ver1 <- cbind("httr",as.character(packageVersion("httr")))
pack_ver2 <- cbind("jsonlite",as.character(packageVersion("jsonlite")))
pack_ver3 <- cbind("lubridate",as.character(packageVersion("lubridate")))
pack_ver4 <- cbind("tidyverse",as.character(packageVersion("tidyverse")))
pack_ver5 <- cbind("RMariaDB",as.character(packageVersion("RMariaDB")))
pack_ver6 <- cbind("DT",as.character(packageVersion("DT")))
pack_ver7 <- cbind("knitr",as.character(packageVersion("knitr")))
pack_ver8 <- cbind("kableExtra",as.character(packageVersion("kableExtra")))

pack_versions <- as.data.frame(rbind(pack_ver1,pack_ver2,pack_ver3,pack_ver4,pack_ver5,pack_ver6,pack_ver7,pack_ver8))
colnames(pack_versions) <- c("Package Name", "Version")
kable(pack_versions)
```

### Functions 


<p style="font-family: times, serif; font-size:16pt; font-style:italic">**json_to_df**</p> 
+ accesses our financial data API and returns a cleaned DF
+ inputs
    + tag(char)
        + stock ticker 

<p style="font-family: times, serif; font-size:16pt; font-style:italic">**Build_table**</p> 

+ function will take the result of **json_to_df**, a dataframe with stock financial information, and run a query to create an sql table with that dataframe
+ Returns an error if table already exists, prompting user to rename table or run the **update_table** function
+ To prevent duplicate data, the function creates a primary key based on date+company tag 
+ Inputs
    + tag(char)
        + stock ticker
    + table_name(char)
        + user choice for my_sql table name

<p style="font-family: times, serif; font-size:16pt; font-style:italic">**Update table** </p> 

+ Function loops over a list of stock market tags and inserts them into a previously created my_sql db
+ Function has error handling so that it will refuse to add a df from the loop, if it detects duplicate data in the query table
    + If dataframe has duplicates an error will print to screen that "data for {tag} was not added" and the loop will move onto next item in list
    + if dataframe is inserted successfully, function will print to screen to indicate is was updated
+ Inputs
    + tags (list of chars)
    + table_name(char)
        + user choice for my_sql table name

 
        
```{r}
### Function accesses financial data API and returns a dataframe ready to be inserted into SQL 
### Function takes companies stock tag as an input string   
json_to_df <- function(tag)
    {
    ## Build url
    url <- paste("https://financialmodelingprep.com/api/v3/financials/income-statement/",tag,"?period=quarter",sep="")
    headers = c('Upgrade-Insecure-Requests' = '1')
    params = list(`datatype` = 'json')
    
    ## Make request
    result <- GET(url = url, httr::add_headers(.headers=headers), query = params)
    result<- rawToChar(result$content)
    df <- as.data.frame(fromJSON(result)[2])
    
    ## Fix table column names- remove financials. and special char "."
    colnames(df) <- gsub("financials.|\\.","",colnames(df))
    
    ## Convert Date to datetime/ rename date as reportdate
    df$Report_Date <- as.Date(df$date, '%Y-%m-%d')
    df <-  df %>%
        select(-date)
    
    ## Build tag column to identify stock ticker
    df$Company <- tag
    
    ## Build primary key column convert financial data to numeric
    df$Id <- paste(as.character(df$Report_Date),df$Company,sep="-")
    cols.num <- colnames(df)[1:31]
    df[,cols.num] <- sapply(df[cols.num],as.numeric)
    
    ## Data check for NA-
    table(is.na(df))
    return(df)
}


### Function initalizes table creation in mysql
### takes stock tag(chracter), tablename(character)
### If table already exists, will tell you to use different name or use update function instead
build_table <- function(tag,tablename){
    
        ## import df from json api call function 
        df <- json_to_df(tag)
    
        ## grab credentials from credential file
        db_credentials<-"C:\\Users\\justin\\Desktop\\xmedia.cnf"
        my_sql_db<-"xmedia"
        
        ## make connection
        my_conn<-dbConnect(RMariaDB::MariaDB(),
                           default.file=db_credentials,
                           group=my_sql_db)

        ## Build table from df
        tryCatch(dbWriteTable(my_conn, value = df, 
                              name = tablename,
                              overwrite =FALSE,
                              row.names = FALSE) ,error= function(e){print("table can not be overwritten and already exists. Please use update table function or change name")})
        
        ## Set primary key to Companytag+Date
        res <- dbSendQuery(my_conn, paste("ALTER TABLE",tablename,"ADD CONSTRAINT websites_pk
                                 PRIMARY KEY (`Id`(40)) ;"))
        ## Disconnect
        dbClearResult(res)
        dbDisconnect(my_conn)
}


### loops through list of stock tags and updates SQL DB 
### Will not update db if any of stock data in new queried df already exists in SQL DB
update_table <- function(tags,tablename){
    for (tag in tags){
        
        ## set error checker
        skip_to_next <- FALSE
        
        ## import df from json api call function 
        df <- json_to_df(tag)
        
        ## grab credentials from credential file
        db_credentials<-"C:\\Users\\justin\\Desktop\\xmedia.cnf"
        my_sql_db<-"xmedia"
        
        ## make connection
        my_conn<-dbConnect(RMariaDB::MariaDB(),
                           default.file=db_credentials,
                           group=my_sql_db) 
        
        # insert df into SQL.  Catches primary key conflicts(duplicate data), prints stock wasnt updated, and moves on in loop
        tryCatch(dbWriteTable(my_conn, value = df, 
                          name = tablename, 
                          overwrite= FALSE,   
                          append = TRUE,                         
                          row.names = FALSE),error= function(e){skip_to_next <<- TRUE})
         if(skip_to_next) { print(paste("Company",tag, "data already exists in DB"))
                            gc()
                            dbDisconnect(my_conn)
                            next }
        gc()
        dbDisconnect(my_conn)
        print(paste("db was updated correctly with: ",tag ))
    }
}


```


### Call functions and build db {.tabset .tabset-fade}
+ create a list of banks to explore
+ run functions to insert that list into mysql db

```{r}

top_10_banks <- c('WFC', 'PNC', 'BBT', 'STI', 'KEY', 'MTB', 'HBAN', 'ZION', 'CMA', 'FITB',"CFG")
## build a table in sql
build_table('USB',"financials")
update_table(top_10_banks,"financials")
```

### Explore SQL DB

+ Experiment with sql db

```{r}
## practice some query with db
db_credentials<-"C:\\Users\\justin\\Desktop\\xmedia.cnf"
my_sql_db<-"xmedia"
my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db) 

## print out description of table
print(dbGetQuery(my_conn, "DESCRIBE financials;"))

## Check for NA values
res <- dbGetQuery(my_conn, "SELECT * FROM financials;")
table(is.na(res))

## look at sql db
res <- dbGetQuery(my_conn, "SELECT * FROM financials;")
datatable(res)
gc()
dbDisconnect(my_conn)
```




##   windows functions {.tabset .tabset-fade}


I am looking at 10 of the largest publicly traded banks by cap size.  Windows functions can be useful to compare value over different periods.  The main windows functions we use below are LAG, DENSERANK and ROWS. Lag is used to create a growth column.  Quarterly data can suffer from seasonality, therefore, we can use lag set with 4, to compare the YOY(year over year) quarterly growth.  The lag gets us the performance of any statistic from the preceding year of the matching quarter(for Q1 2019 lag returns Q1 2018).  We then just use a simple growth formula to measure percentage change. The next function builds a ranking based on growth.  The last function represents how one would build a cumulative sum

### Build windows functions

+ Functions will be called again in there section, but they are listed here with some inline notes

```{r}

### Uses Lag to build Year over year quarterly growth for desired columns
yty_growth <- function(statistic,table_name){
    my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db) 
       query <- paste("WITH Last_Year  AS (SELECT Company,Report_Date,",statistic,", LAG(",statistic, ",4) OVER( PARTITION BY Company ORDER BY Report_Date)  Last_Year_",statistic," FROM ",table_name,") SELECT Company,Report_Date,",statistic, ",Last_Year_",statistic,", ROUND((Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,"*-1,3) AS Growth FROM Last_Year;",sep="" )
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
}


### Uses dense rank to rank to first develop a growth percent by any col and then rank those growth rates
### Function inputs are statistic, table name, partition set
### if input partition is set to 1, then function will rank individual Company performance
### If partition is not set to 1, function will return ranks of the aggregate banking industry

yty_ranking <- function(statistic,table_name,partition=0){
    ##Build connection
    my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db)
    
    ##Build query without partition
    if (partition==0){
    query <- paste("WITH Last_Year  AS (SELECT Company,Report_Date,",
                   statistic,", LAG(",statistic, ",4) OVER( PARTITION BY Company ORDER BY Report_Date) Last_Year_",statistic,
                   " FROM ",table_name," ),", statistic,"_table AS (SELECT Company,Report_Date,",statistic,
                   ",Last_Year_",statistic,", ROUND((-1*Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,
                   ",3) AS Growth FROM Last_Year) SELECT *, CASE WHEN Growth IS NOT NULL then DENSE_RANK() OVER ( ORDER BY Growth desc) end) AS ranked_Growth FROM ",statistic,"_table;",sep="")
    ## Send query request and display result
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
    }
    
    ##Build query with partition
    else {
        query <- paste("WITH Last_Year  AS (SELECT Company,Report_Date,",statistic,", LAG(",statistic, ",4) OVER( PARTITION BY Company ORDER BY Report_Date) Last_Year_",statistic," FROM ",table_name," ),", statistic,"_table AS (SELECT Company,Report_Date,",statistic,",Last_Year_",statistic,", ROUND((Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,"*-1,3) AS Growth FROM Last_Year) SELECT *, (CASE WHEN Growth IS NOT NULL then DENSE_RANK() OVER ( PARTITION BY Company ORDER BY Growth desc) end) AS ranked_Growth FROM ",statistic,"_table;",sep="")
    
    ## Send query request and display result
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
    }
}

## aggregate data to yearly data and build out running yearly average for last 3 years
## Query does not take any inputs, it's to show how you would create cumulative sum value FROM customer
## Instead of getting cumulative sum, I took average of past 3 years, and forced Null values for years 2009 and 2010
yearly_cum_sum_revenue <- function()
{
    my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db)
    query <- paste(
    " WITH yearly_revenue AS (SELECT Company, Year(Report_Date) AS years, sum(revenue) AS revenues FROM financials GROUP BY Company,",
    "Year(Report_Date) ORDER BY Company,Year(Report_Date)) SELECT *, CASE WHEN years not in (2009,2010)	then sum(revenues) OVER",
    "(ORDER BY Company, years rows between 3 preceding and current row) else null end AS 'Three_Year_Running_Avg' FROM yearly_revenue ORDER BY Company,years;", sep="" )
    
    ## Send query request and display result
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
}           
         
```

### Execute yty_Growth with Revenue 

+  Inputs 
    + statistic (any numeric column)
    + tablename (any character value) 
+  Returns YOY Growth rate for company performance
+  Creates a CTE table Last_Year that uses a lag of 4 to grab the last year quarterly results and builds that column as a new column
+  The function finishes by building a Growth rate based on last year revenue versus this year revenue.

```{r}
### Uses Lag to build Year over year quarterly Growth for desired columns
yty_growth <- function(statistic,table_name){
    my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db) 
       query <- paste("WITH Last_Year AS (SELECT Company,Report_Date,",statistic,", LAG(",statistic, ",4) Over( PARTITION BY Company ORDER BY Report_Date)  Last_Year_",statistic," FROM ",table_name,") SELECT Company,Report_Date,",statistic, ",Last_Year_",statistic,", ROUND((Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,"*-1,3) AS Growth FROM Last_Year;",sep="" )
       print(query)
    res <- dbGetQuery(my_conn,query)
    write.csv(res, file = paste("yty_growth",statistic,".csv",sep="" ))
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
}

yty_growth("Revenue","financials")
```


### Execute yty_Growth with operating expenses
+ Function is identical to function in previous section
    + See Execute yty_growth with Revenue section for explanation of function 

```{r}
yty_growth <- function(statistic,table_name){
    my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db) 
       query <- paste("WITH Last_Year  AS (SELECT Company,Report_Date,",statistic,", LAG(",statistic, ",4) Over( PARTITION BY Company ORDER BY Report_Date)  Last_Year_",statistic," FROM ",table_name,") SELECT Company,Report_Date,",statistic, ",Last_Year_",statistic,", ROUND((Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,"*-1,3) AS growth FROM Last_Year;",sep="" )
    print(query)
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
}

yty_growth("OperatingExpenses","financials")

```

### Execute yty_ranking grouped by Company

+ Function takes a statistic (revenue, assets etc), creates a growth rate based on that statistic (mimics our original growth function), and then creates a ranking using dense_rank().
+ The query uses a CTE to build the growth rate table(Last_Year), it then uses another CTE to call Last_Year debt and build our growth_rate for that statistic and finally it uses the results FROM the 2nd CTE and runs dense rank of the growth_rate over a window based on time with the option to additionally Partition the window on industry level or Company level.
+ We can set partition, which determines if we execute the if or else block.
+ If partition is set to 0, it will execute the query as grouped at the industry level.  
    + The below function returns rank at the industry level

```{r}
yty_ranking <- function(statistic,table_name,partition=0){
    ##Build connection
    my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db)
    
    ##Build query without partition
    if (partition==0){
    query <- paste("WITH Last_Year  AS (SELECT Company,Report_Date,",
                   statistic,", LAG(",statistic, ",4) Over( PARTITION BY Company ORDER BY Report_Date) Last_Year_",statistic,
                   " FROM ",table_name," ),", statistic,"_table AS (SELECT Company,Report_Date,",statistic,
                   ",Last_Year_",statistic,", ROUND((-1*Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,
                   ",3) AS growth FROM Last_Year) SELECT *, (CASE WHEN growth IS NOT NULL then DENSE_RANK() OVER ( ORDER BY growth desc) end) AS ranked_growth FROM ",statistic,"_table;",sep="")
    print(query)
    
    ## Send query request and display result
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
    }
    
    ##Build query with partition
    else {
        query <- paste("WITH Last_Year  AS (SELECT Company,Report_Date,",statistic,", LAG(",statistic, ",4) Over( PARTITION BY Company ORDER BY Report_Date) Last_Year_",statistic," FROM ",table_name," ),", statistic,"_table AS (SELECT Company,Report_Date,",statistic,",Last_Year_",statistic,", ROUND((Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,"*-1,3) AS growth FROM Last_Year) SELECT *, (CASE WHEN growth IS NOT NULL then DENSE_RANK() OVER ( PARTITION BY Company ORDER BY growth desc) end) AS ranked_growth FROM ",statistic,"_table;",sep="")
    print(query)
    ## Send query request and display result
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
    }
}

yty_ranking("Revenue","financials")
```


### Execute yty_ranking grouped by industry

**same function as previous section **
+ Function takes a statistic (revenue, assets  etc), creates a growth rate based on that statistic(mimics our original growth function), and then creates a ranking using dense_rank().
+ The query uses a CTE to build the growth rate table(Last_Year), it then uses another CTE to call Last_Year debt and build our growth_rate for that statistic and finally it uses the results from the 2nd CTE and runs dense rank of the growth_rate over a window based on time with the option to additionally Partition the window on industry level or Company level.
+ We can set partition, which determines if we execute the if or else block.
+ If partition is set to any number other than 0, it will execute the query as grouped at the Company level.  
    + The below function returns rank at the Company level


```{r}
yty_ranking <- function(statistic,table_name,partition=0){
    ##Build connection
    my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db)
    
    ##Build query without partition
    if (partition==0){
    query <- paste("WITH Last_Year  AS (SELECT Company,Report_Date,",
                   statistic,", LAG(",statistic, ",4) OVER( PARTITION BY Company ORDER BY Report_Date) Last_Year_",statistic,
                   " FROM ",table_name," ),", statistic,"_table AS (SELECT Company,Report_Date,",statistic,
                   ",Last_Year_",statistic,", ROUND((-1*Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,
                   ",3) AS growth FROM Last_Year) SELECT *, (case when growth is not null then dense_rank() OVER ( ORDER BY growth desc) end) AS ranked_growth FROM ",statistic,"_table;",sep="")
    print(query)
    
    ## Send query request and display result
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
    }
    
    ##Build query with partition
    else {
        query <- paste("WITH Last_Year  AS (SELECT Company,Report_Date,",statistic,", LAG(",statistic, ",4) OVER( PARTITION BY Company ORDER BY Report_Date) Last_Year_",statistic," FROM ",table_name," ),", statistic,"_table AS (SELECT Company,Report_Date,",statistic,",Last_Year_",statistic,", ROUND((Last_Year_",statistic,"-",statistic,")/Last_Year_",statistic,"*-1,3) AS growth FROM Last_Year) SELECT *, (case when growth is not null then dense_rank() OVER ( PARTITION BY Company ORDER BY growth desc) end) AS ranked_growth FROM ",statistic,"_table;",sep="")
    print(query)
    
    ## Send query request and display result
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
    }
}

yty_ranking("Revenue","financials",partition=1)
```

### Execute yearly cumulative sum

+ This function is more for show than utility
+ As the directions suggested a windows function tracking cumsum values for customers, it mimics that by creating yearly revenue and grabbing the average of yearly revenue over a window including the 2 years prior.
    + Grabbing the three year average was uneccessary. I could have just created cumsum for revenue, but as that value doesn't mean much here, I figured I would add some moving parts to the query
+ One dangerous part of the query is if data is incomplete it will return some averages that may not be 3 year averages. In order to return Null for the first 2 values(2009 and 2010) I created a case when to return null for 2009 and 2010
    + If a Company doesn't start in 2009, say it went public in 2011, then it's first and second running total would be "wrong".  
    + In our case all data is complete 

```{r}
yearly_cum_sum_revenue <- function()
{
    my_conn<-dbConnect(RMariaDB::MariaDB(),
                   default.file=db_credentials,
                   group=my_sql_db)
    query <- paste(
    " WITH yearly_revenue AS (SELECT Company, Year(Report_Date) AS years, sum(revenue) AS revenues FROM financials GROUP BY Company,",
    "Year(Report_Date) ORDER BY Company,Year(Report_Date)) SELECT *, CASE WHEN years NOT IN (2009,2010)	THEN SUM(revenues) OVER",
    "(ORDER BY Company, years ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) ELSE NULL END AS 'Three_Year_Running_Avg' FROM yearly_revenue ORDER BY Company,years;", sep="" )
    
    ## Send query request and display result
    res <- dbGetQuery(my_conn,query)
    datatable(res)
    gc()
    dbDisconnect(my_conn)
    return(datatable(res))
}         

yearly_cum_sum_revenue()
```



##   Data Exploration  {.tabset .tabset-fade}




